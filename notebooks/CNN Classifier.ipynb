{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02d3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np, torch, torchmetrics, pytorch_lightning as pl\n",
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from efficientnet_pytorch.model import EfficientNet\n",
    "\n",
    "from kymatio.torch import TimeFrequencyScattering1D\n",
    "\n",
    "from kymjtfs.batch_norm import ScatteringBatchNorm\n",
    "\n",
    "\n",
    "\n",
    "class MedleySolosClassifier(LightningModule):\n",
    "    def __init__(self, in_shape = 2**16, J = 12, Q = 16, F = 4, T = 2**11, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_shape = in_shape\n",
    "        self.J = J\n",
    "        self.Q = Q\n",
    "        self.F = F\n",
    "        self.T = T\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.s1_conv1 = nn.Sequential(\n",
    "            Unsqueeze(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=(16, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(4, 1), padding=(2, 0))\n",
    "        )\n",
    "        \n",
    "        self.setup_jtfs()\n",
    "        \n",
    "        self.conv_net = EfficientNet.from_name('efficientnet-b0',\n",
    "                                               in_channels=self.jtfs_channels,\n",
    "                                               include_top = True,\n",
    "                                               num_classes = 8)\n",
    "        \n",
    "        self.acc_metric = torchmetrics.AveragePrecision(num_classes = 8)\n",
    "\n",
    "    def setup_jtfs(self):\n",
    "        self.jtfs = TimeFrequencyScattering1D(\n",
    "            shape=(self.in_shape, ),\n",
    "            T=self.T,\n",
    "            Q=self.Q,\n",
    "            J=self.J,\n",
    "            F=self.F,\n",
    "            average_fr=True,\n",
    "            max_pad_factor=1, \n",
    "            max_pad_factor_fr=1,\n",
    "            out_3D=True,)\n",
    "        \n",
    "        n_channels = self._get_jtfs_out_dim()\n",
    "        \n",
    "        self.jtfs_dim = self._get_jtfs_out_dim()\n",
    "        self.jtfs_channels = self.jtfs_dim[0]\n",
    "        self.jtfs_bn = ScatteringBatchNorm(self.jtfs_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        Sx = self.jtfs(x)\n",
    "        \n",
    "        s1, s2 = Sx[0], Sx[1]\n",
    "        s1_conv = self.s1_conv1(s1)\n",
    "        s1_conv = F.pad(s1_conv, \n",
    "                   (0, 0, s2.shape[-2] - s1_conv.shape[-2], 0))\n",
    "        \n",
    "        sx = torch.cat([s1_conv, s2], dim=1)[:, :, :32, :]\n",
    "        sx = torch.log1p(self.jtfs_bn(sx))\n",
    "        y = self.conv_net(sx)\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y\n",
    "    \n",
    "        \n",
    "    def step(self, batch, fold):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        loss, acc = F.nll_loss(logits, y), self.acc_metric(logits, y)\n",
    "        \n",
    "        self.log(f'{fold}/loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "#         self.log(f'{fold}/acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "#         return {f'loss': loss, f'{fold}/acc': acc}\n",
    "        return {f'loss': loss}\n",
    "    \n",
    "    def log_metrics(self, outputs, fold):\n",
    "        keys = list(outputs[0].keys())\n",
    "        for k in keys:\n",
    "            metric = torch.stack([x[k] for x in outputs]).mean()\n",
    "            self.log(f'{fold}/{k}', metric)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, fold='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, fold='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, fold='test')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return opt\n",
    "    \n",
    "    def _get_jtfs_out_dim(self):\n",
    "        dummy_in = torch.randn(self.in_shape).cuda()\n",
    "        sx = self.jtfs(dummy_in)\n",
    "        s1 = self.s1_conv1(sx[0])\n",
    "        s1 = F.pad(s1, (0, 0, sx[1].shape[-2] - s1.shape[-2], 0))\n",
    "        S = torch.cat([s1, sx[1]], dim=1)[:, :, :32, :]\n",
    "        out_dim = S.shape[1:3]\n",
    "        return out_dim\n",
    "    \n",
    "class Unsqueeze(nn.Module):\n",
    "    def __init__(self, dim=1):\n",
    "        super(Unsqueeze, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.unsqueeze(self.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2db529",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167070d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mirdata.datasets.medley_solos_db as msdb\n",
    "\n",
    "\n",
    "\n",
    "class MedleySolosDB(Dataset):\n",
    "    def __init__(self, data_dir='/import/c4dm-datasets/medley-solos-db/', subset='training'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.msdb = msdb.Dataset(data_dir)\n",
    "        self.audio_dir = os.path.join(data_dir, 'audio')\n",
    "        self.csv_dir = os.path.join(data_dir, 'annotation')\n",
    "        self.subset = subset\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(self.csv_dir, 'Medley-solos-DB_metadata.csv'))\n",
    "        self.df = df.loc[df['subset'] == subset]\n",
    "        self.df.reset_index(inplace = True)\n",
    "        \n",
    "    def build_audio_fname(self, df_item):\n",
    "        uuid = df_item['uuid4']\n",
    "        instr_id = df_item['instrument_id']\n",
    "        subset = df_item['subset']\n",
    "        return f'Medley-solos-DB_{subset}-{instr_id}_{uuid}.wav'\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        audio_fname = self.build_audio_fname(item)\n",
    "        audio, _ = msdb.load_audio(os.path.join(self.audio_dir, audio_fname))\n",
    "        y = int(item['instrument_id'])\n",
    "        \n",
    "        return audio, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "\n",
    "class MedleyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 data_dir: str = '/import/c4dm-datasets/medley-solos-db/', \n",
    "                 batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.train_ds = MedleySolosDB(self.data_dir, subset='training')\n",
    "        self.val_ds = MedleySolosDB(self.data_dir, subset='validation')\n",
    "        self.test_ds = MedleySolosDB(self.data_dir, subset='test')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=80)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, drop_last=True, num_workers=80)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle=False, drop_last=True, num_workers=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d99d54",
   "metadata": {},
   "source": [
    "### Mock Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02087b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3772, -2.1299, -1.6823, -2.5611, -1.5263, -2.1659, -2.1802, -2.5235],\n",
       "        [-2.2936, -1.7534, -2.0579, -1.8844, -2.2263, -1.9018, -2.4726, -2.2568],\n",
       "        [-1.8175, -2.1123, -2.4692, -2.2959, -1.8422, -2.0866, -2.1370, -2.0349],\n",
       "        [-2.1562, -2.6873, -2.1296, -2.8890, -2.5012, -1.5817, -1.7269, -1.7361]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_loader = MedleySolosDB()\n",
    "train_ds = DataLoader(train_loader, batch_size=64)\n",
    "model = MedleySolosClassifier()\n",
    "model(torch.randn(4, 2**16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058df32",
   "metadata": {},
   "source": [
    "### Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97158554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "n_epochs, batch_size = 200, 4\n",
    "early_stop_callback = EarlyStopping(monitor=\"val/loss\", \n",
    "                                    min_delta=0.00, \n",
    "                                    patience=3, \n",
    "                                    verbose=False, \n",
    "                                    mode=\"max\")\n",
    "trainer = pl.Trainer(gpus=-1, \n",
    "                     max_epochs=n_epochs,\n",
    "                     progress_bar_refresh_rate=1, \n",
    "                     checkpoint_callback=True,\n",
    "                     callbacks=[early_stop_callback])\n",
    "model, dataset = MedleySolosClassifier(), MedleyDataModule(batch_size=batch_size) \n",
    "trainer.fit(model, dataset)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad4a9e",
   "metadata": {},
   "source": [
    "### Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b301e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ckpt = '/homes/cv300/Documents/scattering/lightning_logs/version_15/checkpoints/epoch=9-step=14599.ckpt'\n",
    "model = MedleySolosClassifier.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc25a95134c48e09e9c2e2c6e864f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cv300/venvs/dafx/lib/python3.8/site-packages/torchmetrics/functional/classification/average_precision.py:166: UserWarning: Average precision score for one or more classes was `nan`. Ignoring these classes in average\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "test_loader = MedleySolosDB(subset='test')\n",
    "test_ds = DataLoader(test_loader, batch_size=4)\n",
    "\n",
    "trainer = Trainer(gpus=-1, progress_bar_refresh_rate=1)\n",
    "trainer.test(model, test_dataloaders=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52865c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12236"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cdb0dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3167\n",
       "7    2900\n",
       "4    2609\n",
       "2    1142\n",
       "1     955\n",
       "0     732\n",
       "6     406\n",
       "5     325\n",
       "Name: instrument_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.df['instrument_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf8df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
