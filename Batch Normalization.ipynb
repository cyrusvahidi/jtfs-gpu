{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ScatteringBatchNorm(nn.Module):\n",
    "    ''' A general purpose batch normalization layer,\n",
    "        designed particularly for scattering paths.\n",
    "    \n",
    "    Args:\n",
    "        num_features: the number of scattering paths\n",
    "        c: an optionally learnable multiplicative featurewise constant, used\n",
    "            before taking the logarithm to gaussianize the histogram of scattering \n",
    "            path values.\n",
    "    '''\n",
    "    def __init__(self, num_features, c: float = None, eval_mode: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features \n",
    "        self.mu = torch.zeros(self.num_features)\n",
    "        self.c = torch.nn.Parameter(torch.zeros(self.num_features)) if not c else c\n",
    "\n",
    "        self.eval_mode = eval_mode\n",
    "\n",
    "    def _check_input_dim(self, input):\n",
    "        if input.dim() != 2 and input.dim() != 3:\n",
    "            raise ValueError(\n",
    "                \"expected 2D or 3D input (got {}D input)\".format(input.dim())\n",
    "            )\n",
    "        if input.shape[-1] != self.num_features:\n",
    "            raise ValueError(\n",
    "                \"expected last dim to equal feature dim: {} (got {}D input)\".format(self.num_features, input.shape[-1])\n",
    "            )\n",
    "\n",
    "    def forward(self, sx)\n",
    "        self._check_input_dim(sx)\n",
    "        \n",
    "        if not self.eval_mode:\n",
    "            batch_size = sx.shape[0]\n",
    "            batch_mu =  (1 / batch_size) * torch.sum(sx, dim=0)\n",
    "            \n",
    "            self.mu = (1 / (batch_size + 1)) * self.mu.type_as(sx) + (batch_size / (batch_size + 1)) * batch_mu\n",
    "\n",
    "        sx = torch.log1p(torch.exp(self.c) * sx / (1e-3 + self.mu))\n",
    "        return sx \n",
    "\n",
    "    def eval(self):\n",
    "        self.eval_mode = True\n",
    "        return self.train(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
